

2ï¸âƒ£ Technical Architecture
```
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Raw Data (CSV/JSON)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  HDFS Data Lake (Raw Zone)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Hive Clean Zone (Parquet) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Star Schema Tables    â”‚
                    â”‚ dim_students / dim_dateâ€¦  â”‚
                    â”‚ fact_attendance           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Flask Backend (REST API)       â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Frontend Dashboard (UI Team)    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

3ï¸âƒ£ Dataset Description

Synthetic data was generated using Python (generate_data.py).

Included Tables (Clean Zone â€“ CSV)

datasets/clean/dim_students.csv

datasets/clean/dim_classes.csv

datasets/clean/dim_semesters.csv

datasets/clean/dim_date.csv

datasets/clean/fact_attendance.csv

| Table           | Rows             |
| --------------- | ---------------- |
| dim_students    | 2,000,000        |
| dim_classes     | 4001             |
| dim_semesters   | 87               |
| dim_date        | 3 years of dates |
| fact_attendance | 2,000,000        |
Raw zone files (CSV + JSONL) are not included in GitHub to avoid large file limits.



5ï¸âƒ£ Backend API (Flask)

Backend code is in:
`backend/app.py`

install dependencies
```
python3 -m venv venv
```
```
source venv/bin/activate
```
```
pip install -r backend/requirements-min.txt
```

Run server
python backend/app.py

API Root
http://localhost:5000

| Endpoint            | Description                           |
| ------------------- | ------------------------------------- |
| `/health`           | Check if datasets loaded successfully |
| `/students/count`   | Total students                        |
| `/grades/by-gender` | Avg grade per gender                  |
| (Extendable)        | Add more endpoints easily             |


6ï¸âƒ£ For the Frontend/UI Team
â­ This is everything the UI team needs.

You do not need Hadoop or Hive.
You only need the CSVs and the Flask API.

ğŸ”§ Step 1: Clone the project
```git clone https://github.com/AhmadAlSalous/school-bigdata-project2.git```
```cd school-bigdata-project2```

ğŸ§° Step 2: Create a virtual environment
### Linux / macOS
```
python3 -m venv venv
```
```
source venv/bin/activate
```

### Windows (PowerShell)
```
python -m venv venv
```
```
venv\Scripts\activate
```

ğŸ“¦ Step 3: Install API dependencies
```
pip install -r backend/requirements-min.txt
```


Files included:

Flask==3.0.0
flask-cors==4.0.0

ğŸ“ Step 4: Ensure clean CSVs exist

Inside:

datasets/clean/


You should see:

dim_students.csv

dim_classes.csv

dim_semesters.csv

dim_date.csv

fact_attendance.csv

If not â†’ tell Ahmad to re-commit them.

â–¶ï¸ Step 5: Start the backend API
```
python backend/app.py
```


You should see:

[SERVER] Starting Flask API...
 * Running on http://localhost:5000

ğŸŒ Step 6: Test API Endpoints
Health
GET http://localhost:5000/health

Students count
GET http://localhost:5000/students/count

Grades by gender
GET http://localhost:5000/grades/by-gender

ğŸ¨ Step 7: Using the API in React / JavaScript

Example:

useEffect(() => {
  fetch("http://localhost:5000/students/count")
    .then(res => res.json())
    .then(data => setStudentCount(data.total_students))
}, []);


Bar chart example:

useEffect(() => {
  fetch("http://localhost:5000/grades/by-gender")
    .then(res => res.json())
    .then(data => setGenderStats(data));
}, []);


You can now build:

KPI cards

Gender grade chart

Class performance chart

Attendance trends

Student-detail pages

Everything the UI needs comes from the API.

7ï¸âƒ£ Project File Structure
```
school-bigdata-project2/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements-min.txt
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ clean/
â”‚       â”œâ”€â”€ dim_students.csv
â”‚       â”œâ”€â”€ dim_classes.csv
â”‚       â”œâ”€â”€ dim_date.csv
â”‚       â”œâ”€â”€ dim_semesters.csv
â”‚       â””â”€â”€ fact_attendance.csv
â”‚
â”œâ”€â”€ generate_data.py
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

âœ” What You ALREADY support fully

These sections are 100% ready with your current backend + clean CSVs:

ğŸ”¹ Section 1 â€” KPIs

âœ” Total Students â†’ /students/count

âœ” Total Classes â†’ can get from CSV or add tiny API

âœ” Total Attendance Records â†’ can get from CSV or add tiny API

âœ” Average Grade â†’ can calculate from fact_attendance

ğŸ”¹ Section 2 â€” Students Analytics

You can build these using backend or frontend processing:

âœ” Gender distribution â†’ backend: /grades/by-gender OR directly from students.csv

âœ” Students by nationality â†’ frontend can read CSV directly

âœ” Students per grade level â†’ frontend or small API

âœ” Student table â†’ frontend can load CSV

ğŸ”¹ Section 3 â€” Grades Analytics

âœ” Average grade by gender â†’ /grades/by-gender

âœ” Grade distribution histogram â†’ from CSV (fact_attendance)

âœ” Trend of grades by date â†’ from fact_attendance.csv + dim_date.csv (frontend join)

ğŸ”¹ Section 4 â€” Attendance Analytics

You already have the data you need:

âœ” Attendance by month â†’ fact_attendance + dim_date join

âœ” Attendance by weekday â†’ dim_date

âœ” Attendance by semester â†’ fact_attendance + dim_semesters

These can be done either:

Via frontend loading CSVs OR

With 2â€“3 small API endpoints

ğŸ”¹ Section 5 â€” Class Analytics

âœ” Students per class â†’ from students.csv

âœ” Classes per grade level â†’ dim_classes.csv

ğŸ”¹ Section 6 â€” Semesters

âœ” Table of semesters â†’ dim_semesters.csv

â— But here is what is missing

Just 3â€“4 tiny backend endpoints will make the dashboard MUCH easier for your UI team:

ğŸ”¸ Missing Endpoint 1 â€” /classes/count

Returns total number of classes
â†’ trivial to add, 3 lines of code

ğŸ”¸ Missing Endpoint 2 â€” /attendance/count

Returns 2M attendance rows
â†’ also trivial

ğŸ”¸ Missing Endpoint 3 â€” /attendance/by-month

UI team will love this
â†’ small groupby

ğŸ”¸ Missing Endpoint 4 â€” /attendance/by-weekday

Useful chart

â­ But even without these APIs, the UI team CAN STILL BUILD THE DASHBOARD

Why?

Because all clean CSVs are already available in:

datasets/clean/*.csv


Meaningâ€¦

The UI can load CSVs directly using:

JavaScript CSV parser (Papaparse) or Python (if using Streamlit)

They donâ€™t NEED the backend at all to draw charts.
The CSVs are clean, high-quality, and have complete dimensions + fact table.

ğŸ§  So what is the BEST approach for your timeline?
Option A â€” Fastest (UI team loads CSV directly)

âœ” No backend work needed
âœ” UI team can start immediately
âœ” They just import CSVs and do charts

Recommended because you have 4 days left

Option B â€” Clean API layer (Adds polish to the project)

You add 4â€“5 simple endpoints:

Endpoint	Purpose
/students/count	Already exists
/grades/by-gender	Already exists
/classes/count	Missing
/attendance/count	Missing
/attendance/by-month	Missing
/attendance/by-weekday	Missing

This looks more professional in your presentation.

ğŸ† My Recommendation for You

Because you want to impress:

âœ” Let the UI team work directly with CSVs (fastest + safest)
âœ” You add the missing 4 small endpoints later for extra polish

This way:

Your UI team doesnâ€™t wait

Your backend isnâ€™t a blocker

Your project has BOTH a data lake + API + dashboard

Your professor will be impressed by the completeness

ğŸ”¥ Summary (very important)
You CAN build the entire dashboard RIGHT NOW using only CSVs.
ğŸ’¡ You DO NOT need any more data.

You DO NOT need new pipelines.
You DO NOT need to regenerate anything.

Only OPTIONAL backend polishing remains:

attendance count

classes count

attendance by month

attendance by weekday
